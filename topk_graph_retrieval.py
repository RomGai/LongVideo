import torch
import torch.nn.functional as F
import networkx as nx
import core.vision_encoder.pe as pe
import core.vision_encoder.transforms as transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ===== 1ï¸âƒ£ åŠ è½½å›¾ç»“æ„ =====
import pickle

with open("spatio_temporal_graph.pkl", "rb") as f:
    G = pickle.load(f)

print(f"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\n")

# ===== 2ï¸âƒ£ åˆå§‹åŒ–æ¨¡å‹ä¸æ–‡æœ¬æŸ¥è¯¢ =====
model_name = 'PE-Core-G14-448'
model = pe.CLIP.from_config(model_name, pretrained=True).to(device)
tokenizer = transforms.get_text_tokenizer(model.context_length)

query = "Chopping Tree in Minecraft"
text = tokenizer([query]).to(device)

with torch.no_grad():
    text_features = model.encode_text(text)
    text_features = text_features / text_features.norm(dim=-1, keepdim=True)

# ===== 3ï¸âƒ£ è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹ä¸æ–‡æœ¬çš„ç›¸ä¼¼åº¦ =====
similarities = []
for i in range(G.number_of_nodes()):
    img_feat = G.nodes[i]["feature"].to(device)
    img_feat = img_feat / img_feat.norm()
    sim = torch.dot(img_feat, text_features.squeeze(0)).item()
    similarities.append((i, sim))

# æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
similarities.sort(key=lambda x: x[1], reverse=True)
top1_node, top1_sim = similarities[0]

print("=== ğŸ” Top-1 Most Similar Node ===")
print(f"Node {top1_node} | path={G.nodes[top1_node]['path']}")
print(f"Similarity: {top1_sim:.4f}")
print("-" * 80)

# ===== 4ï¸âƒ£ æ‰¾å‡º Top-3 ç©ºé—´è¾¹ =====
spatial_neighbors = [
    (j, G.edges[top1_node, j]["weight"])
    for j in G.neighbors(top1_node)
    if G.edges[top1_node, j]["type"] == "spatial"
]
spatial_neighbors = sorted(spatial_neighbors, key=lambda x: x[1], reverse=True)[:3]

print("=== ğŸ§­ Top-3 Spatial Neighbors (by edge weight) ===")
for rank, (j, w) in enumerate(spatial_neighbors, 1):
    print(f"[{rank}] Node {j} | weight={w:.4f} | path={G.nodes[j]['path']}")
print("-" * 80)

# ===== 5ï¸âƒ£ æ”¶é›†è¿™äº›èŠ‚ç‚¹åŠå®ƒä»¬çš„ temporal é‚»å±… =====
selected_nodes = {top1_node}
selected_nodes.update([j for j, _ in spatial_neighbors])

# åŠ å…¥ temporal é‚»å±…
for n in list(selected_nodes):
    for j in G.neighbors(n):
        if G.edges[n, j]["type"] == "temporal":
            selected_nodes.add(j)

print("=== ğŸ•“ Final Collected Nodes (Top-1 + 3 spatial + temporal neighbors) ===")
for nid in sorted(selected_nodes):
    tag = " <-- [Top-1]" if nid == top1_node else ""
    print(f"Node {nid} | {G.nodes[nid]['path']}{tag}")

# å¯é€‰ï¼šè¿”å›å¯¹åº”è·¯å¾„åˆ—è¡¨
# selected_paths = [G.nodes[nid]["path"] for nid in sorted(selected_nodes)]

import json

# ===== âœ… ä»…ä¿å­˜è¢«é€‰ä¸­èŠ‚ç‚¹çš„è§†é¢‘è·¯å¾„ =====
selected_paths = [G.nodes[nid]["path"] for nid in sorted(selected_nodes)]

# æ‰“å°æŸ¥çœ‹
print(f"\n[âœ“] å…±é€‰å‡º {len(selected_paths)} ä¸ªè§†é¢‘ï¼š")
for p in selected_paths:
    print("  ", p)

# ä¿å­˜ä¸º jsonï¼ˆæ›´æ–¹ä¾¿é˜…è¯»ï¼‰
with open("selected_video_paths.json", "w", encoding="utf-8") as f:
    json.dump(selected_paths, f, indent=4, ensure_ascii=False)

print("\n[âœ“] å·²ä¿å­˜åˆ° 'selected_video_paths.json'")

# ===== ä¹‹ååŠ è½½ =====
# with open("selected_video_paths.json", "r", encoding="utf-8") as f:
#     paths = json.load(f)